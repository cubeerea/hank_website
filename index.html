<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description"
        content="[Your Name] — Early-career AI practitioner. Learning velocity, applied reasoning, research-adjacent work.">
    <title>Hank Sha</title>
    <link rel="stylesheet" href="css/style.css">
</head>

<body>
    <main class="container">
        <!-- Landing / Orientation Section -->
        <header class="section section--hero">
            <h1 class="hero__title">Hank Sha</h1>
            <p class="hero__subtitle">Early-career AI practitioner. I ramp quickly in unfamiliar domains and apply
                reasoning under uncertainty.</p>

            <div class="hero__interests">
                <span class="interest-tag">mechanistic interpretability</span>
                <span class="interest-tag">alignment</span>
                <span class="interest-tag">applied ML</span>
            </div>

            <div class="hero__meta">
                <p>This is a living document. It replaces a traditional resume and reflects how I think and learn,
                    supported by concrete work.</p>
                <p>Updated as I learn. Built in public.</p>
                <p class="hero__timestamp">Last updated: <time datetime="2026-01-25">January 25, 2026</time></p>
            </div>
        </header>

        <!-- About Section -->
        <section class="section" id="about">
            <h2 class="section__title">About</h2>
            <p>I'm a undergraduate senior studying Statistics & Data Science, working across AI research and
                engineering. I'm
                interested in problems where modeling, systems, and product constraints intersect—especially in applied
                ML and LLM-based systems.</p>
            <p>I've worked on production ML systems at early-stage startups, contributed to peer-reviewed research, and
                enjoy operating in ambiguous, fast-moving environments. This site reflects how I think, learn, and
                evaluate technical tradeoffs.</p>
        </section>

        <!-- Learning Philosophy Section -->
        <section class="section" id="philosophy">
            <h2 class="section__title">Learning Philosophy</h2>
            <p><strong>Skills as investments.</strong> I view skills as investments rather than virtues. Every new skill
                has an opportunity cost in time, energy, and focus, so gaps are often the result of intentional
                prioritization rather than lack of ability. My learning decisions are guided by expected leverage—how
                much a skill expands my ability to reason about systems, deliver impact, or adapt to new problem
                spaces—rather than by checklist completeness.</p>
        </section>

        <!-- How I Learn & Ramp (Primary Section) -->
        <section class="section section--primary" id="learning">
            <h2 class="section__title">How I Learn & Ramp</h2>
            <p class="section__intro">My approach to entering unfamiliar domains. Role-agnostic; applies to research,
                engineering, and hybrid work.</p>

            <ul class="ramp-list">
                <li>
                    <strong>Start with a high-level map, then drill down.</strong> I often begin with summaries or
                    overviews to orient myself, but I don't stop there. I move quickly to primary sources—papers,
                    documentation, raw artifacts—and build my own understanding from first principles.
                </li>
                <li>
                    <strong>Get hands-on early and iterate.</strong> Rather than waiting to "fully understand" a
                    concept, I get directly involved with it—experimenting, breaking things, and improving through
                    mistakes. Progress comes from iteration, not polished first attempts.
                </li>
                <li>
                    <strong>Think in counterexamples, edge cases, and first principles.</strong> I stress-test ideas by
                    asking when they fail, what assumptions they rely on, and where intuition breaks. This helps
                    distinguish surface-level understanding from structural understanding.
                </li>
                <li>
                    <strong>Course-correct explicitly.</strong> When my understanding turns out to be wrong or
                    incomplete, I document what failed and why. The goal is to update my mental model, not defend it.
                </li>
                <li>
                    <strong>Write as I go.</strong> Writing forces clarity. Publishing (when appropriate) creates
                    accountability and invites correction, which accelerates learning.
                </li>
            </ul>
        </section>

        <!-- Skill Map Section -->
        <section class="section" id="skills">
            <h2 class="section__title">Skill Map</h2>
            <p class="section__intro">An honest self-assessment. Gaps are current learning priorities, not apologies.
            </p>
            <div class="skill-grid">
                <div class="skill-column skill-column--strong">
                    <h3 class="skill-column__title">Strong</h3>
                    <ul class="skill-list">
                        <li>Python (NumPy, PyTorch, pandas)</li>
                        <li>Technical writing</li>
                        <li>Paper reading & synthesis</li>
                        <li>Rapid domain ramp-up</li>
                        <li>Identifying what matters vs. what doesn't</li>
                        <li>Asking clarifying questions</li>
                        <li>Communicating uncertainty</li>
                    </ul>
                </div>
                <div class="skill-column skill-column--moderate">
                    <h3 class="skill-column__title">Moderate</h3>
                    <ul class="skill-list">
                        <li>Transformer architectures</li>
                        <li>Experiment design</li>
                        <li>Statistical modeling</li>
                        <li>Collaborative research</li>
                        <li>JavaScript / web development</li>
                        <li>Working with ambiguous requirements</li>
                    </ul>
                </div>
                <div class="skill-column skill-column--gaps">
                    <h3 class="skill-column__title">Gaps (Learning Now)</h3>
                    <ul class="skill-list">
                        <li>CUDA / GPU programming</li>
                        <li>Large-scale distributed training</li>
                        <li>Interpretability tooling (TransformerLens, etc.)</li>
                        <li>Publishing in peer-reviewed venues</li>
                        <li>Leading multi-person research projects</li>
                    </ul>
                </div>
            </div>
        </section>

        <!-- Learning in Public Section -->
        <section class="section" id="writing">
            <h2 class="section__title">Building/Learning in Public</h2>
            <div class="writing-intro">
                <p>I write to clarify my own thinking. Publishing creates accountability and invites correction from
                    people who know more than I do.</p>
                <p>This is intellectual exploration, not expertise. My understanding evolves; older posts may reflect
                    superseded views.</p>
            </div>

            <div class="writing-links">
                <h3 class="writing-links__title">Selected Writing</h3>
                <ul class="writing-list">
                    <li>
                        <a href="https://medium.com/@cubeerea/ai-prompts-i-use-everyday-37f71a7b3cde"
                            class="writing-list__link">5 AI Prompts That Will Seriously Save You 20+ Hours a Week (Free
                            Guide)</a>
                        <span class="writing-list__meta">— Sharing AI prompts in my workflow.</span>
                    </li>
                    <li>
                        <a href="https://medium.com/@cubeerea/5-steps-to-memorizing-the-autograd-implementation-for-good-9e49b683fe9c"
                            class="writing-list__link">Under the Hood of Neural Networks: Implementing Autograd from
                            Scratch</a>
                        <span class="writing-list__meta">— Technical notes on Autograd implementation.</span>
                    </li>
                </ul>
                <p class="writing-cta">
                    <a href="https://medium.com/@cubeerea">More writing on Medium →</a>
                </p>
            </div>
        </section>

        <!-- Selected Work & Experiences (Evidence Layer) -->
        <section class="section" id="work">
            <h2 class="section__title">Selected Work</h2>
            <p class="section__intro">Applications of the above. Each follows: Context (domain, uncertainty,
                constraints) → Action (what I learned, evaluated, built) → Lessons (judgment, tradeoffs, generalizable
                insights).</p>

            <!-- Biotech / Clinical Trials -->
            <article class="experience-card" data-expanded="false">
                <button class="experience-card__header" aria-expanded="false">
                    <div class="experience-card__summary">
                        <h3 class="experience-card__title">Clinical Data Science Internship</h3>
                        <span class="experience-card__meta">Pre-IPO Biotech · Phase II MDD Trial</span>
                    </div>
                    <span class="experience-card__toggle" aria-hidden="true">+</span>
                </button>
                <div class="experience-card__content">
                    <div class="experience-card__section">
                        <h4>Context</h4>
                        <p>Analyzed Phase II clinical trial data for an MDD drug at a pre-IPO biotech company.
                            Objective: use ML and statistical methods to identify potential gaps, latent signals, or
                            patterns not captured by traditional analyses. I had no prior experience in clinical trials
                            or biostatistics.</p>
                        <p>Constraints: small trial size, limited data points, high noise, and significant placebo
                            effects—conditions that are common in psychiatric trials and fundamentally limit what ML can
                            detect.</p>
                    </div>
                    <div class="experience-card__section">
                        <h4>Action</h4>
                        <p><strong>Domain ramp-up:</strong> Navigated extensive clinical trial documentation, unfamiliar
                            terminology, trial protocols, and outcome measures. Synthesized enough context to work
                            effectively within weeks.</p>
                        <p><strong>Exploratory analysis:</strong> Conducted deep EDA—placebo response patterns, subgroup
                            analyses, outcome distribution shifts. Compared findings against traditional statistical
                            outputs to evaluate where additional methods might add signal versus noise.</p>
                        <p><strong>ML experimentation:</strong> Trained multiple classification models to explore
                            whether ML could surface patterns missed by standard analyses. XGBoost performed best among
                            the models tested. However, accuracy and precision were unstable across folds; performance
                            was insufficient for any production or decision-support use. Made a deliberate judgment that
                            these results should not be over-interpreted or presented as actionable.</p>
                    </div>
                    <div class="experience-card__section">
                        <h4>Lessons</h4>
                        <ul>
                            <li>Knowing when ML doesn't apply is part of the job. Small, noisy clinical datasets often
                                lack the statistical power for ML to add value. Recognizing this early prevents wasted
                                effort and misleading conclusions.</li>
                            <li>EDA and domain understanding matter more than model complexity. The most useful insights
                                came from careful exploratory analysis, not from algorithmic sophistication.</li>
                            <li>Negative results are still results. Concluding that ML was not appropriate for this
                                dataset was the correct scientific judgment—not a failure.</li>
                            <li>Unfamiliar domains become navigable quickly with focused reading. Clinical trial
                                structure, terminology, and conventions are learnable; the key is knowing what to
                                prioritize.</li>
                        </ul>
                    </div>
                </div>
            </article>

            <!-- Research Role -->
            <article class="experience-card" data-expanded="false">
                <button class="experience-card__header" aria-expanded="false">
                    <div class="experience-card__summary">
                        <h3 class="experience-card__title">Research Assistant</h3>
                        <span class="experience-card__meta">2025-Present · Yuzhou Chen's Lab · LLMs, Graph
                            Unlearning</span>
                    </div>
                    <span class="experience-card__toggle" aria-hidden="true">+</span>
                </button>
                <div class="experience-card__content">
                    <div class="experience-card__section">
                        <h4>Context</h4>
                        <p>Research assistant on projects involving large language models, graph unlearning, and
                            topological graph structures. Primary responsibilities: replicating results from existing
                            papers, implementing experimental pipelines, and supporting ongoing research. Second author
                            on a paper exploring the use of LLMs for node and graph unlearning tasks.</p>
                        <p>Constraints: limited compute budget, tight publication timelines, no dedicated
                            infrastructure.</p>
                    </div>
                    <div class="experience-card__section">
                        <h4>Action</h4>
                        <p><strong>Model inference & systems work:</strong> Set up local inference for an open-source
                            Hugging Face model on my own machine. Worked directly with CUDA, VRAM constraints, and
                            memory optimization. Evaluated vLLM as a serving framework for improved throughput;
                            determined that setup complexity and time constraints made it impractical for this project.
                            Made a deliberate decision to revert to a simpler CUDA-based configuration. Optimized
                            quantization settings and achieved ~4× speedup in experiment runtime.</p>
                        <p><strong>Data collection & tooling:</strong> Tasked with collecting datasets related to AI
                            conference discourse on X (Twitter)—follower graphs, post content, engagement data. Assessed
                            that building a custom scraping solution would be slow, brittle, and blocked by rate limits
                            and firewalls. Recommended using existing third-party tools. No single tool satisfied all
                            requirements, so I combined multiple tools to assemble the dataset—effectively a
                            "frankensteined" pipeline that prioritized speed and reliability over elegance.</p>
                    </div>
                    <div class="experience-card__section">
                        <h4>Lessons</h4>
                        <ul>
                            <li>Sophistication has overhead. A simpler CUDA setup outperformed a more advanced serving
                                framework given the constraints. Knowing when not to use a tool is as important as
                                knowing how.</li>
                            <li>Economic thinking applies to research. Time spent building infrastructure is time not
                                spent running experiments. I learned to evaluate build-vs-buy tradeoffs quickly.</li>
                            <li>Execution quality matters. Replication work and pipeline implementation aren't
                                glamorous, but they're where most research actually happens. Doing them reliably builds
                                trust.</li>
                            <li>Scrappy solutions can be correct solutions. The data pipeline wasn't elegant, but it
                                worked, and the alternative would have taken weeks longer.</li>
                        </ul>
                    </div>
                </div>
            </article>

            <!-- Venture Scout -->
            <article class="experience-card" data-expanded="false">
                <button class="experience-card__header" aria-expanded="false">
                    <div class="experience-card__summary">
                        <h3 class="experience-card__title">Venture Scout</h3>
                        <span class="experience-card__meta">2025–Present · Bouken Capital</span>
                    </div>
                    <span class="experience-card__toggle" aria-hidden="true">+</span>
                </button>
                <div class="experience-card__content">
                    <div class="experience-card__section">
                        <h4>Context</h4>
                        <p>Part-time scout role at an early-stage fund (pre-seed, seed, early Series A) investing across
                            AI, deep tech, energy, cleantech, and web3. This was a sourcing and light evaluation
                            role—not deal-leading or deep diligence. I did not make or influence investment decisions.
                        </p>
                    </div>
                    <div class="experience-card__section">
                        <h4>Action</h4>
                        <p><strong>Sourcing & outreach:</strong> Sourced startups through university venture clubs,
                            campus events, and founder communities. Conducted high-volume cold outreach via email and
                            LinkedIn. Learned that many student startups were too early for fundraising, and that
                            effective sourcing requires persistence and tolerance for rejection and non-responses.</p>
                        <p><strong>Evaluation & research:</strong> Performed light startup evaluation—value proposition
                            clarity, market opportunity, team background, early traction, competitive landscape.
                            Reviewed pitch decks with a critical but early-stage lens. Summarized findings for partners
                            and answered basic diligence questions when asked.</p>
                        <p><strong>Internal coordination:</strong> Communicated regularly with firm partners. Provided
                            concise updates and timely responses. Helped advise and onboard newer scouts.</p>
                    </div>
                    <div class="experience-card__section">
                        <h4>Lessons</h4>
                        <ul>
                            <li>Communication is foundational. Clarity, tone, and responsiveness matter more than I
                                expected. This role was a training ground for professional communication—cold
                                approaches, follow-ups, handling rejection without disengaging.</li>
                            <li>Early-stage evaluation is different. At pre-seed, there's little data; the work is about
                                identifying potential under uncertainty, not validating traction.</li>
                            <li>Cold outreach is a learned skill. I started uncomfortable with it; I improved through
                                repetition. Rejection is normal and not personal.</li>
                            <li>This role pushed me outside my comfort zone socially, which was valuable independent of
                                any specific outcome.</li>
                        </ul>
                    </div>
                </div>
            </article>

            <!-- GitRoll Internship -->
            <article class="experience-card" data-expanded="false">
                <button class="experience-card__header" aria-expanded="false">
                    <div class="experience-card__summary">
                        <h3 class="experience-card__title">AI/ML Engineer Intern</h3>
                        <span class="experience-card__meta">2024-2025 · GitRoll (HR-Tech, Pre-Seed)</span>
                    </div>
                    <span class="experience-card__toggle" aria-hidden="true">+</span>
                </button>
                <div class="experience-card__content">
                    <div class="experience-card__section">
                        <h4>Context</h4>
                        <p>GitRoll is a pre-seed HR-tech startup that scans GitHub repositories to evaluate developer
                            contributions—designed to surface signal beyond resumes and help underrepresented developers
                            get fairer evaluations.</p>
                        <p><strong>How I got here:</strong> As a junior without a summer internship, I attended a demo
                            event at Draper University specifically to network and find opportunities. After initial
                            conversations with the founders, I interviewed but felt I performed poorly due to
                            inexperience. I proposed working unpaid for 1–2 weeks so they could evaluate my contribution
                            before committing. Instead, they gave me a take-home project: evaluate and tune prompts for
                            their LLM-based grading system. Given two weeks, I completed it in one. The work exceeded
                            expectations; I received an offer.</p>
                    </div>
                    <div class="experience-card__section">
                        <h4>Action</h4>
                        <p><strong>LLM & NLP systems:</strong> Led R&D for a uniqueness grading model using LLMs and NLP
                            techniques. The system has been applied to 1.4M+ users. Proposed and implemented improved
                            grading metrics, prompt engineering strategies, and output calibration for consistency.</p>
                        <p><strong>Model evaluation & cost optimization:</strong> Benchmarked LLMs (GPT, Gemini, Claude)
                            for cost and performance tradeoffs. Reduced LLM-related costs by ~13% through model
                            selection and prompt optimization.</p>
                        <p><strong>Repository analysis & bias reduction:</strong> Scanned and analyzed 200+ GitHub
                            repositories. Iterated on grading logic through user collaboration and internal feedback.
                            Improved model performance by ~20% over previous versions. Explicitly worked on bias
                            reduction and fairness-aware evaluation.</p>
                        <p><strong>Supervised learning & labeling:</strong> Manually labeled 216+ GitHub pull request
                            issues. Built classification models achieving ~92% precision. Experimented with word-bank
                            approaches and NLTK-based categorization. Classified issues into 3 impact levels; this logic
                            was integrated into contribution scoring and CURISM metrics.</p>
                        <p><strong>Static analysis & tooling:</strong> Used ast-grep for code linting and analysis.
                            Built a programming language progression roadmap (Python, JavaScript, TypeScript) for
                            developers. Improved internal development velocity by ~30%.</p>
                    </div>
                    <div class="experience-card__section">
                        <h4>Lessons</h4>
                        <ul>
                            <li>Opportunities can be created, not just found. Proposing a trial period was uncomfortable
                                but effective. Execution speaks louder than credentials.</li>
                            <li>Early-stage startups reward breadth. I touched LLM systems, labeling, static analysis,
                                and product iteration—all within a few months. Context-switching is the job.</li>
                            <li>Fairness in ML is a design problem, not just a metrics problem. Bias reduction required
                                iterating on grading logic with real users, not just adjusting thresholds.</li>
                            <li>Speed matters at pre-seed. Completing the take-home in half the time signaled more than
                                the work itself.</li>
                        </ul>
                    </div>
                </div>
            </article>
        </section>

        <!-- Footer -->
        <footer class="section section--footer">
            <div class="footer__contact">
                <h2 class="section__title">Contact</h2>
                <ul class="contact-list">
                    <li><a href="mailto:you@example.com">hankssha@gmail.com</a></li>
                    <li><a href="https://github.com/yourusername">GitHub</a></li>
                    <li><a href="https://medium.com/@cubeerea">Medium</a></li>
                    <li><a href="https://www.linkedin.com/in/hank-sha/">LinkedIn</a></li>
                </ul>
            </div>
            <div class="footer__resume">
                <p>Traditional format: <a href="assets/hank_sha_resume.pdf" download>resume.pdf</a></p>
            </div>
        </footer>
    </main>

    <script src="js/main.js"></script>
</body>

</html>